{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSa4tWhIDSu6cQnvln3GOs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thevirusoup/thevirusoup/blob/main/DATA_HORSE_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "H100wC7pna6z",
        "outputId": "f2625dfd-fdab-436a-9017-cd8e3f50a301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyplink\n",
            "  Downloading pyplink-1.3.7-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from pyplink) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyplink) (2.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from pyplink) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.17.1->pyplink) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.17.1->pyplink) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.17.1->pyplink) (2025.1)\n",
            "Downloading pyplink-1.3.7-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pyplink\n",
            "Successfully installed pyplink-1.3.7\n"
          ]
        }
      ],
      "source": [
        "pip install pyplink\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyplink\n"
      ],
      "metadata": {
        "id": "O9-5eFuKn7r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division"
      ],
      "metadata": {
        "id": "mxhjaEFBn_s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyplink import PyPlink"
      ],
      "metadata": {
        "id": "W65Z1NM3oC-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pedfile = PyPlink(r'/home/hp/Documents/ML/Horse_AIMS')"
      ],
      "metadata": {
        "id": "vPWKb1hzoQIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"{:,d} samples and {:,d} markers\".format(\n",
        "    pedfile.get_nb_samples(),\n",
        "    pedfile.get_nb_markers(),\n",
        "))"
      ],
      "metadata": {
        "id": "H1TDPSXioiBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_samples = pedfile.get_fam()\n",
        "all_samples.head()"
      ],
      "metadata": {
        "id": "2kMjZjHsoqFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_markers = pedfile.get_bim()\n",
        "all_markers.head()"
      ],
      "metadata": {
        "id": "l_rbW-8ppCEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additive format: Cycling through genotypes as -1, 0, 1 and 2 values, where -1 is unknown, 0 is homozygous (major allele), 1 is heterozygous, and 2 is homozygous (minor allele).\n",
        "import numpy as np\n",
        "\n",
        "# Initialize empty lists to store marker_id and genotypes\n",
        "marker_ids_list = []\n",
        "genotypes_list = []\n",
        "\n",
        "# Iterate over marker_id and genotypes in pedfile\n",
        "for marker_id, genotypes in pedfile:\n",
        "    # Append marker_id and genotypes to the respective lists\n",
        "    marker_ids_list.append(marker_id)\n",
        "    genotypes_list.append(genotypes)\n",
        "\n",
        "# Convert the lists into numpy arrays\n",
        "marker_ids_array = np.array(marker_ids_list)\n",
        "genotypes_array = np.array(genotypes_list)\n",
        "\n",
        "# Transpose the genotypes_array to have genotypes in rows\n",
        "genotypes_array = np.transpose(genotypes_array)\n",
        "\n",
        "matrix = np.vstack((marker_ids_array, genotypes_array))\n",
        "\n",
        "# Save the matrix to a text file\n",
        "np.savetxt('Horse_try.txt', matrix, delimiter='\\t', fmt='%s')\n"
      ],
      "metadata": {
        "id": "UwDoYuzMpHpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the main data file\n",
        "main_file = 'Horse_try.txt'\n",
        "main_df = pd.read_csv(main_file, delimiter='\\t')\n",
        "\n",
        "# Load the new column data file, including its header\n",
        "new_column_file = 'labels_horse.txt'\n",
        "new_column_df = pd.read_csv(new_column_file, delimiter='\\t')\n",
        "\n",
        "# Extract the column name and values from the new column DataFrame\n",
        "new_column_name = new_column_df.columns[0]\n",
        "new_column_values = new_column_df[new_column_name]\n",
        "\n",
        "# Insert the new column at the first position (index 0)\n",
        "main_df.insert(0, new_column_name, new_column_values)\n",
        "\n",
        "# Save the modified DataFrame to a .csv file\n",
        "output_file = 'Horse_try.csv'\n",
        "main_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f'New column from \"{new_column_file}\" has been added as the first column and saved to {output_file}.')\n"
      ],
      "metadata": {
        "id": "K62fBHhlpR51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Nucleotide format Cycling through genotypes as A, C, G and T values (where 00 is unknown)\n",
        "import numpy as np\n",
        "\n",
        "# Initialize empty lists to store marker_id and genotypes\n",
        "marker_ids_list = []\n",
        "genotypes_list = []\n",
        "\n",
        "# Iterate over marker_id and genotypes in pedfile\n",
        "for marker_id, genotypes in pedfile.iter_acgt_geno():\n",
        "      # Append marker_id and genotypes to the respective lists\n",
        "    marker_ids_list.append(marker_id)\n",
        "    genotypes_list.append(genotypes)\n",
        "\n",
        "# Convert the lists into numpy arrays\n",
        "marker_ids_array = np.array(marker_ids_list)\n",
        "genotypes_array = np.array(genotypes_list)\n",
        "\n",
        "# Transpose the genotypes_array to have genotypes in rows\n",
        "genotypes_array = np.transpose(genotypes_array)\n",
        "\n",
        "matrix = np.vstack((marker_ids_array, genotypes_array))\n",
        "\n",
        "# Save the matrix to a text file\n",
        "np.savetxt('RP_N_matrix.txt', matrix, delimiter='\\t', fmt='%s')\n"
      ],
      "metadata": {
        "id": "DxeEb91ApU6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "file_path = r\"C:\\Users\\kkoka\\Desktop\\Python learning\\RP_DFI_80%AC_encoded.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Separate the features (SNPs) and the target variable (breed)\n",
        "features = data.iloc[:, 1:]  # Exclude the first column (breed)\n",
        "target = data.iloc[:, 0]  # First column (breed)\n",
        "\n",
        "# Impute missing values with the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "imputed_features = imputer.fit_transform(features)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(imputed_features, target, test_size=0.25, random_state=42)\n",
        "\n",
        "# Create and train the Random Forest Classifier\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "QX_G7pLKpY97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "file_path = r\"C:\\Users\\kkoka\\Desktop\\Python learning\\RP_DFI_80%AC_encoded.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Separate the features (SNPs) and the target variable (breed)\n",
        "features = data.iloc[:, 1:]  # Exclude the first column (breed)\n",
        "target = data.iloc[:, 0]  # First column (breed)\n",
        "\n",
        "# Create a Random Forest Classifier\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 5\n",
        "\n",
        "# Perform stratified k-fold cross-validation\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies = []  # To store accuracy for each fold\n",
        "\n",
        "# Iterate over the folds\n",
        "for train_index, test_index in skf.split(features, target):\n",
        "    # Split the data into training and testing sets for the current fold\n",
        "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
        "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
        "\n",
        "    # Perform Recursive Feature Elimination with Cross-Validation (RFECV)\n",
        "    rfecv = RFECV(estimator=clf, step=1, cv=skf)\n",
        "    rfecv.fit(X_train, y_train)\n",
        "\n",
        "    # Get the selected feature indices and names\n",
        "    selected_indices = rfecv.get_support(indices=True)\n",
        "    selected_features = X_train.columns[selected_indices]\n",
        "\n",
        "    # Train the classifier using the selected features\n",
        "    clf.fit(X_train[selected_features], y_train)\n",
        "\n",
        "    # Make predictions on the test set using the selected features\n",
        "    y_pred = clf.predict(X_test[selected_features])\n",
        "\n",
        "    # Calculate the accuracy for the current fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracies) / n_splits\n",
        "\n",
        "# Get the selected features with the highest accuracy\n",
        "best_indices = rfecv.get_support(indices=True)\n",
        "best_features = features.columns[best_indices]\n",
        "\n",
        "# Print the selected features\n",
        "print(\"Selected Features:\")\n",
        "print(best_features)\n",
        "\n",
        "# Check if accuracy exceeds 90%\n",
        "if average_accuracy > 0.9:\n",
        "    # Save the selected features to a text file\n",
        "    with open(\"selected_features.txt\", \"w\") as file:\n",
        "        for feature in best_features:\n",
        "            file.write(feature + \"\\n\")\n",
        "    print(\"Selected features saved to selected_features.txt\")\n",
        "else:\n",
        "    print(\"Unable to achieve accuracy > 90% with the selected features.\")\n"
      ],
      "metadata": {
        "id": "q4AOUn4jpcmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "file_path = r\"C:\\Users\\kkoka\\Desktop\\Python learning\\RP_DFI_80%AC_encoded.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Separate the features (SNPs) and the target variable (breed)\n",
        "features = data.iloc[:, 1:]  # Exclude the first column (breed)\n",
        "target = data.iloc[:, 0]  # First column (breed)\n",
        "\n",
        "# Perform missing value imputation\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "imputed_features = pd.DataFrame(imputer.fit_transform(features), columns=features.columns)\n",
        "\n",
        "# Create a Random Forest Classifier\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Define the number of splits for cross-validation\n",
        "n_splits = 3\n",
        "\n",
        "# Perform stratified shuffle-split cross-validation\n",
        "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.2, random_state=42)\n",
        "\n",
        "accuracies = []  # To store accuracy for each split\n",
        "\n",
        "# Iterate over the splits\n",
        "for train_index, test_index in sss.split(imputed_features, target):\n",
        "    # Split the data into training and testing sets for the current split\n",
        "    X_train, X_test = imputed_features.iloc[train_index], imputed_features.iloc[test_index]\n",
        "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
        "\n",
        "    # Perform feature selection using SelectKBest with chi2 scoring\n",
        "    selector = SelectKBest(score_func=f_classif, k=70)\n",
        "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "\n",
        "    # Train the classifier using the selected features\n",
        "    clf.fit(X_train_selected, y_train)\n",
        "\n",
        "    # Make predictions on the test set using the selected features\n",
        "    y_pred = clf.predict(X_test_selected)\n",
        "\n",
        "    # Calculate the accuracy for the current split\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Calculate the average accuracy across all splits\n",
        "average_accuracy = sum(accuracies) / n_splits\n",
        "\n",
        "# Get the selected feature indices\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get the selected features with the highest accuracy\n",
        "best_features = imputed_features.columns[selected_indices]\n",
        "\n",
        "# Print the selected features\n",
        "print(\"Selected Features:\")\n",
        "print(best_features)\n",
        "\n",
        "# Check if accuracy exceeds 85%\n",
        "if average_accuracy > 0.85:\n",
        "    # Save the selected features to a text file\n",
        "    with open(\"selected_features2.txt\", \"w\") as file:\n",
        "        for feature in best_features:\n",
        "            file.write(feature + \"\\n\")\n",
        "    print(\"Selected features saved to selected_features2.txt\")\n",
        "else:\n",
        "    print(\"Unable to achieve accuracy > 85% with the selected features.\")\n"
      ],
      "metadata": {
        "id": "G5MX8iC0qmJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "file_path = r\"C:\\Users\\kkoka\\Desktop\\Python learning\\RP_DFI_80%AC_encoded.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Separate the features (SNPs) and the target variable (breed)\n",
        "features = data.iloc[:, 1:]  # Exclude the first column (breed)\n",
        "target = data.iloc[:, 0]  # First column (breed)\n",
        "\n",
        "# Perform missing value imputation\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "imputed_features = pd.DataFrame(imputer.fit_transform(features), columns=features.columns)\n",
        "\n",
        "# Perform feature selection using SelectKBest with chi2 scoring\n",
        "selector = SelectKBest(score_func=f_classif, k=100)\n",
        "selected_features = selector.fit_transform(imputed_features, target)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a Random Forest Classifier\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Train the classifier using the selected features\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set using the selected features\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Get the selected feature indices\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get the selected features\n",
        "selected_snps = imputed_features.columns[selected_indices]\n",
        "\n",
        "# Save the selected SNPs to a text file\n",
        "with open(\"selected_snps.txt\", \"w\") as file:\n",
        "    for snp in selected_snps:\n",
        "        file.write(snp + \"\\n\")\n",
        "\n",
        "print(\"Selected SNPs saved to selected_snps.txt\")\n"
      ],
      "metadata": {
        "id": "uTkrlyqQq6sT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}