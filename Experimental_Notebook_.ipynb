{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPRfulXjkZgm9PMBW8HfSw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thevirusoup/thevirusoup/blob/main/Experimental_Notebook_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hello, Tanzil!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwE8B2RM7L2k",
        "outputId": "4984289f-658d-4410-e2bd-ccd3215f7f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, Tanzil!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wallet = 100/-\n",
        "# movie 1 = 80/-\n",
        "# movie 2 = 120/-"
      ],
      "metadata": {
        "id": "V9ChGjgF_YW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wallet_price = 100\n",
        "movie_1 = 80\n",
        "\n",
        "if wallet_price > movie_1:\n",
        " print(\"Go to Movie\")\n",
        "\n",
        "else :\n",
        " print(\"Go to home\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMN49mYC_4B0",
        "outputId": "a96497a8-7d93-4c98-951c-298d01a65ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to Movie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install plotly\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ6oKkKjos17",
        "outputId": "3d98f531-4d4c-449d-ec82-420a735f181f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Load built-in country dataset\n",
        "fig = px.choropleth(locations=[\"USA\", \"IND\", \"CAN\", \"FRA\", \"BRA\", \"AUS\", \"CHN\"],  # Add more country codes as needed\n",
        "                    locationmode=\"ISO-3\",\n",
        "                    title=\"Hover over a country to see its name\")\n",
        "\n",
        "# Update layout for better visualization\n",
        "fig.update_layout(\n",
        "    geo=dict(showcoastlines=True, showland=True),\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "4EcQkoEbpTkf",
        "outputId": "51bd66b7-8303-4842-f84c-269e5a79b895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"eed12de2-8afb-4268-8b8f-4435974c576e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"eed12de2-8afb-4268-8b8f-4435974c576e\")) {                    Plotly.newPlot(                        \"eed12de2-8afb-4268-8b8f-4435974c576e\",                        [{\"colorscale\":[[0.0,\"#636efa\"],[1.0,\"#636efa\"]],\"geo\":\"geo\",\"hovertemplate\":\"locations=%{location}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"locationmode\":\"ISO-3\",\"locations\":[\"USA\",\"IND\",\"CAN\",\"FRA\",\"BRA\",\"AUS\",\"CHN\"],\"name\":\"\",\"showlegend\":true,\"showscale\":false,\"z\":[1,1,1,1,1,1,1],\"type\":\"choropleth\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"geo\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"center\":{},\"showcoastlines\":true,\"showland\":true},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Hover over a country to see its name\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('eed12de2-8afb-4268-8b8f-4435974c576e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests beautifulsoup4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UcoN3d-JtY1",
        "outputId": "74af307a-14a9-4e47-f60d-73ede3aa95d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# Function to scrape data from the webpage\n",
        "def scrape_books(url):\n",
        "    try:\n",
        "        # Send HTTP GET request to the URL\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Check if the request was successful (status code 200)\n",
        "        if response.status_code == 200:\n",
        "            print(f\"Successfully fetched the page: {url}\")\n",
        "        else:\n",
        "            print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
        "            return []\n",
        "\n",
        "        # Parse the content of the page with BeautifulSoup\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find all book containers on the page\n",
        "        books = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "        # List to hold the book data\n",
        "        book_data = []\n",
        "\n",
        "        # Loop through each book and extract the title and price\n",
        "        for book in books:\n",
        "            title = book.find('h3').find('a')['title']\n",
        "            price = book.find('p', class_='price_color').text\n",
        "            book_data.append([title, price])\n",
        "\n",
        "        return book_data\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching the page: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to save the scraped data to a CSV file\n",
        "def save_to_csv(book_data, filename):\n",
        "    try:\n",
        "        with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow(['Book Title', 'Price'])  # Writing header row\n",
        "            writer.writerows(book_data)  # Writing the book data rows\n",
        "        print(f\"Data has been successfully saved to {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving to CSV: {e}\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    url = 'http://books.toscrape.com/'\n",
        "    books = scrape_books(url)\n",
        "\n",
        "    if books:\n",
        "        # Print scraped data in a readable format\n",
        "        print(\"\\nBooks and their Prices:\")\n",
        "        for book in books:\n",
        "            print(f\"Title: {book[0]}, Price: {book[1]}\")\n",
        "\n",
        "        # Option to save the data to a CSV file\n",
        "        save_to_csv(books, 'books.csv')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1W-JGkDE-ls",
        "outputId": "d63fe9b0-cd17-4254-db27-5219bc47bbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully fetched the page: http://books.toscrape.com/\n",
            "\n",
            "Books and their Prices:\n",
            "Title: A Light in the Attic, Price: Â£51.77\n",
            "Title: Tipping the Velvet, Price: Â£53.74\n",
            "Title: Soumission, Price: Â£50.10\n",
            "Title: Sharp Objects, Price: Â£47.82\n",
            "Title: Sapiens: A Brief History of Humankind, Price: Â£54.23\n",
            "Title: The Requiem Red, Price: Â£22.65\n",
            "Title: The Dirty Little Secrets of Getting Your Dream Job, Price: Â£33.34\n",
            "Title: The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull, Price: Â£17.93\n",
            "Title: The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics, Price: Â£22.60\n",
            "Title: The Black Maria, Price: Â£52.15\n",
            "Title: Starving Hearts (Triangular Trade Trilogy, #1), Price: Â£13.99\n",
            "Title: Shakespeare's Sonnets, Price: Â£20.66\n",
            "Title: Set Me Free, Price: Â£17.46\n",
            "Title: Scott Pilgrim's Precious Little Life (Scott Pilgrim #1), Price: Â£52.29\n",
            "Title: Rip it Up and Start Again, Price: Â£35.02\n",
            "Title: Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991, Price: Â£57.25\n",
            "Title: Olio, Price: Â£23.88\n",
            "Title: Mesaerion: The Best Science Fiction Stories 1800-1849, Price: Â£37.59\n",
            "Title: Libertarianism for Beginners, Price: Â£51.33\n",
            "Title: It's Only the Himalayas, Price: Â£45.17\n",
            "Data has been successfully saved to books.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium beautifulsoup4 pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_VK27Kur48p",
        "outputId": "a2990d01-f2f7-4caa-cc91-4949e1e06dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2024.12.14)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.1.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.28.1 sortedcontainers-2.4.0 trio-0.28.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Path to your ChromeDriver\n",
        "CHROME_DRIVER_PATH = \"/path/to/chromedriver\"  # Replace with your actual path\n",
        "\n",
        "# Target URL\n",
        "URL = \"https://pubchem.ncbi.nlm.nih.gov/#query=E.coli&tab=pathway\"\n",
        "\n",
        "def fetch_dynamic_page(url):\n",
        "    \"\"\"Fetch dynamic webpage content using Selenium.\"\"\"\n",
        "    try:\n",
        "        # Setup Selenium WebDriver\n",
        "        service = Service(CHROME_DRIVER_PATH)\n",
        "        options = webdriver.ChromeOptions()\n",
        "        options.add_argument(\"--headless\")  # Run in headless mode (no UI)\n",
        "        driver = webdriver.Chrome(service=service, options=options)\n",
        "\n",
        "        # Load the webpage\n",
        "        driver.get(url)\n",
        "        time.sleep(5)  # Wait for JavaScript to load (adjust as needed)\n",
        "\n",
        "        # Get page source and close the driver\n",
        "        page_source = driver.page_source\n",
        "        driver.quit()\n",
        "        return page_source\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching webpage: {e}\")\n",
        "        return None\n",
        "\n",
        "def parse_html(html_content):\n",
        "    \"\"\"Parse the webpage and extract Pathway titles and their associated genes.\"\"\"\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Extract pathway entries (Adjust selectors based on actual webpage structure)\n",
        "    pathways = soup.find_all(\"div\", class_=\"pathway-entry\")  # Update class name as per actual HTML\n",
        "\n",
        "    data = []\n",
        "    for pathway in pathways:\n",
        "        title = pathway.find(\"h2\", class_=\"pathway-title\").get_text(strip=True) if pathway.find(\"h2\", class_=\"pathway-title\") else \"N/A\"\n",
        "        genes = [gene.get_text(strip=True) for gene in pathway.find_all(\"span\", class_=\"gene-name\")]  # Adjust selector\n",
        "        gene_list = \", \".join(genes) if genes else \"No genes listed\"\n",
        "\n",
        "        data.append({\"Pathway Title\": title, \"Genes\": gene_list})\n",
        "\n",
        "    return data\n",
        "\n",
        "def save_to_csv(data, filename=\"pathways_data.csv\"):\n",
        "    \"\"\"Save extracted data to a CSV file.\"\"\"\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Data saved to {filename}\")\n",
        "\n",
        "def main():\n",
        "    html_content = fetch_dynamic_page(URL)\n",
        "\n",
        "    if html_content:\n",
        "        pathways_data = parse_html(html_content)\n",
        "\n",
        "        if pathways_data:\n",
        "            print(\"\\nExtracted Pathway Data:\")\n",
        "            for entry in pathways_data:\n",
        "                print(f\"Pathway: {entry['Pathway Title']}, Genes: {entry['Genes']}\")\n",
        "\n",
        "            # Ask user if they want to save to CSV\n",
        "            save_option = input(\"\\nDo you want to save the data to a CSV file? (yes/no): \").strip().lower()\n",
        "            if save_option == \"yes\":\n",
        "                save_to_csv(pathways_data)\n",
        "        else:\n",
        "            print(\"No pathway data found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to retrieve webpage content.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caMJ7865r8JC",
        "outputId": "026aa136-8d8a-4a56-82f4-c1829b1ed8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching webpage: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve webpage content.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Path to your ChromeDriver\n",
        "CHROME_DRIVER_PATH = \"/path/to/chromedriver\"  # Replace with your actual path\n",
        "\n",
        "# Target URL\n",
        "URL = \"https://www.kegg.jp/kegg-bin/search_pathway\"\n",
        "\n",
        "def fetch_dynamic_page(url):\n",
        "    \"\"\"Fetch dynamic webpage content using Selenium.\"\"\"\n",
        "    try:\n",
        "        # Setup Selenium WebDriver\n",
        "        service = Service(CHROME_DRIVER_PATH)\n",
        "        options = webdriver.ChromeOptions()\n",
        "        options.add_argument(\"--headless\")  # Run in headless mode (no UI)\n",
        "        driver = webdriver.Chrome(service=service, options=options)\n",
        "\n",
        "        # Load the webpage\n",
        "        driver.get(url)\n",
        "        time.sleep(5)  # Wait for JavaScript to load (adjust as needed)\n",
        "\n",
        "        # Get page source and close the driver\n",
        "        page_source = driver.page_source\n",
        "        driver.quit()\n",
        "        return page_source\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching webpage: {e}\")\n",
        "        return None\n",
        "\n",
        "def parse_html(html_content):\n",
        "    \"\"\"Parse the webpage and extract Pathway titles and their associated genes.\"\"\"\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Extract pathway entries (Adjust selectors based on actual webpage structure)\n",
        "    pathways = soup.find_all(\"div\", class_=\"pathway-entry\")  # Update class name as per actual HTML\n",
        "\n",
        "    data = []\n",
        "    for pathway in pathways:\n",
        "        title = pathway.find(\"h2\", class_=\"pathway-title\").get_text(strip=True) if pathway.find(\"h2\", class_=\"pathway-title\") else \"N/A\"\n",
        "        genes = [gene.get_text(strip=True) for gene in pathway.find_all(\"span\", class_=\"gene-name\")]  # Adjust selector\n",
        "        gene_list = \", \".join(genes) if genes else \"No genes listed\"\n",
        "\n",
        "        data.append({\"Pathway Title\": title, \"Genes\": gene_list})\n",
        "\n",
        "    return data\n",
        "\n",
        "def save_to_csv(data, filename=\"pathways_data.csv\"):\n",
        "    \"\"\"Save extracted data to a CSV file.\"\"\"\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Data saved to {filename}\")\n",
        "\n",
        "def main():\n",
        "    html_content = fetch_dynamic_page(URL)\n",
        "\n",
        "    if html_content:\n",
        "        pathways_data = parse_html(html_content)\n",
        "\n",
        "        if pathways_data:\n",
        "            print(\"\\nExtracted Pathway Data:\")\n",
        "            for entry in pathways_data:\n",
        "                print(f\"Pathway: {entry['Pathway Title']}, Genes: {entry['Genes']}\")\n",
        "\n",
        "            # Ask user if they want to save to CSV\n",
        "            save_option = input(\"\\nDo you want to save the data to a CSV file? (yes/no): \").strip().lower()\n",
        "            if save_option == \"yes\":\n",
        "                save_to_csv(pathways_data)\n",
        "        else:\n",
        "            print(\"No pathway data found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to retrieve webpage content.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-xOi2SfsfOV",
        "outputId": "26e75221-bc40-4917-ce94-53fc28d19e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching webpage: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
            "\n",
            "Failed to retrieve webpage content.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 111):\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "E_FOx4-iwUWl",
        "outputId": "fcdf0156-ec86-4c4d-f28d-dc1b22274a17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numbers = [11, 22, 33, 44, 55, 66, 77, 88, 99, 110]\n",
        "for number in numbers:\n",
        "    print(number)"
      ],
      "metadata": {
        "id": "nRPGSzS-ww0e",
        "outputId": "052cd863-ab5c-444a-da4e-351533aa12e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "22\n",
            "33\n",
            "44\n",
            "55\n",
            "66\n",
            "77\n",
            "88\n",
            "99\n",
            "110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numbers = [11, 22, 33, 44, 55, 66, 77, 88, 99, 110, 121, 132, 143, 154, 165, 176, 187, 198, 209]\n",
        "total = 0\n",
        "for number in numbers:\n",
        "    total = total + number\n",
        "print(total)\n",
        ""
      ],
      "metadata": {
        "id": "5XuV3w1QyGZI",
        "outputId": "480c3ec2-d263-44a7-eb70-09416efaa3f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i2s7FthzEBNK"
      }
    }
  ]
}